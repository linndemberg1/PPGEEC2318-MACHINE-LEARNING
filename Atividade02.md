Tarefa - Semana 02
Autor: José Lindenberg de Andrade - 20241009460

I) Análise crítica do artigo: Sobre o impacto social dos modelos de fundações abertas
1. Aspectos positivos:
Os modelos de fundação aberta possibilitam uma maior personalização e uma inspeção mais profunda de como eles operam, oferecendo mais opções aos desenvolvedores por uma ampla quantidade de opções de modelos de fundação.
Devido ao crescimento da inovação e aceleração da ciência, esses modelos têm sido transparentes, permitindo uma melhor investigação sobre os seus efeitos, promovendo  a concorrência e a inovação. Além disso, tem proporcionado uma melhora na investigação científica, na reprodutibilidade e na transparência. E os dados  abertos permitem melhorias/aperfeiçoamento por outros desenvolvedores que têm acesso, deixando feedbacks sobre seu uso, erros de desenvolvimento e propostas de melhorias e até mesmo soluções práticas por quem acessou o material.
Esses modelos de fundação aberta promovem a pesquisa colaborativa através do acesso aberto ao conhecimento, compartilhamento de dados, colaboração entre instituições, financiamento colaborativo e desenvolvimento de padrões comuns na comunidade científica. Essas iniciativas facilitam a troca eficiente de conhecimento, incentivam a transparência e promovem a colaboração entre pesquisadores de diferentes áreas do conhecimento e regiões do mundo.
Facilitam o acesso a recursos e conhecimentos, promovendo a colaboração e o compartilhamento de ideias, desenvolvimento de padrões abertos, busca de financiamento colaborativo e diversificado, e fomentando uma cultura de compartilhamento e aprendizado contínuo. Por fim, promovem a democratização do acesso, trazendo inovação ao garantir um acesso igualitário do conhecimento.

2. Aspectos negativos:
É importante salientar os perigos associados à biossegurança, cibersegurança e propagação de informações falsas. O uso indevido deliberado, como plágio, disseminação de falsidades e atividades fraudulentas, também merecem atenção. Ferramentas digitais podem ser empregadas para modificar imagens de indivíduos sem consentimento, de maneira sexualmente explícita, resultando em consequências graves como chantagem, além de danos emocionais e psicológicos para as vítimas. Tais riscos emergem em modelos de código aberto quando os desenvolvedores renunciam ao controle exclusivo sobre a aplicação do modelo após a liberação dos seus parâmetros. Restrições impostas ao uso subsequente do modelo são desafiadoras de se fazer cumprir e podem ser facilmente desconsideradas por indivíduos com intenções maliciosas.

3. Opinião pessoal:
Acelerar a pesquisa científica é crucial, pois estimula o avanço qualitativo de contribuições deixadas em modelos de código aberto pelos desenvolvedores. A clareza quanto aos direitos autorais, incluindo trabalho, privacidade, práticas de utilização e autoria, é vital em qualquer obra.
 O emprego de inteligência artificial para proteger esses modelos é benéfico, evitando o uso impróprio que possa prejudicar o autor e o público. É essencial enfatizar as possíveis restrições no uso de modelos de código aberto, como limitações de acesso (exigindo, por exemplo, que o usuário seja maior de idade) e propósitos específicos (proibindo o uso em competição com o desenvolvedor do modelo). Ademais, o nível de acesso pode variar com o tempo, desde o lançamento gradual para aumentar a disponibilidade até a descontinuação para restringi-lo.
É essencial estabelecer expectativas claras sobre o uso de dados para prevenir situações adversas. Antecipar como a eficiência e os custos associados à operação dos modelos irão evoluir pode influenciar a avaliação do risco e da escalabilidade do uso indevido. A regulamentação dos criadores de modelos de código aberto é necessária, e embora já existam entidades reguladoras, é preciso reforçar a governança sobre a utilidade desses modelos.
Os modelos de código aberto apresentam riscos de uso indevido por causa da ambiguidade nas expectativas de segurança. Especificamente, a divisão de responsabilidades de segurança entre desenvolvedores e usuários de modelos de código aberto não é bem definida e carece de padrões estabelecidos. Portanto, os desenvolvedores de modelos de código aberto devem ser transparentes sobre as práticas de IA responsáveis que aplicam e as que recomendam ou transferem para desenvolvedores e implementadores. Quando adquirem modelos de código aberto, os usuários devem considerar quais práticas de IA responsáveis já foram implementadas e sua eficácia, e então implementar ou negociar práticas adicionais de IA responsáveis. Isso assegura que as práticas de IA responsáveis não sejam negligenciadas à medida que os desenvolvedores utilizam modelos de código aberto de fornecedores.

Pontos-chave sobre dados de treinamento

Considerando que “os dados são confusos, complexos, imprevisíveis e potencialmente traiçoeiros", como destaca a Chip Huyen no quarto capítulo do livro Designing Machine Learning Systems". Os dados de treinamento em Machine Learning (ML) são cruciais para o sucesso do aprendizado de máquina, pois são usados para construir modelos, evitar overfitting, melhorar a generalização, selecionar recursos importantes e aprimorar continuamente os modelos. Eles são a base sobre a qual os modelos são construídos e refinados.
Aqui destaco 10 insights ou conceitos essenciais sobre dados de treinamento que são mostrados a seguir:
I) Amostragem não probabilística: é uma técnica de seleção de amostras em que os elementos da população não têm uma chance conhecida de serem selecionados. Alguns dos critérios para amostragem não probabilística incluem amostragem por conveniência, julgamento, quotas e bola de neve. Esse tipo de amostragem é menos confiável para inferências estatísticas, mas pode ser a única opção em determinados casos.
II) Amostragem Aleatória Simples: é um método onde cada elemento de uma população têm igual probabilidade de ser escolhido para a amostra. É amplamente utilizada em treinamento e validação de modelos, estimativa de parâmetros e análise exploratória de dados. Além disso, ela garante que a amostra seja imparcial e representativa da população original, sendo fundamental para diversas tarefas em ML.
III) Amostragem Estratificada: é um método que evita a desvantagem da amostragem aleatória simples, onde a população é dividida em grupos e uma amostra é selecionada de cada grupo garantindo representatividade proporcional dos diferentes grupos presentes na população original. Essa abordagem reduz o viés, melhora a precisão das estimativas e é eficiente computacionalmente. É amplamente utilizada para garantir representatividade e precisão em diversas análises e modelagens. Uma desvantagem deste método de amostragem é que nem sempre é possível, como quando é impossível dividir todas as amostras em grupos.
IV) Amostragem Ponderada: este é um método de amostragem onde a seleção de elementos para a amostra é ponderada com base em alguma característica relevante. Isso garante representatividade adequada, especialmente em casos de desequilíbrio de classes ou outros viéses nos dados. É útil para lidar com dados desbalanceados, ajustar viéses de seleção e garantir uma amostra representativa em análises e modelagens em ML. Ela também é muito associada a pesos amostrais, é usada para selecionar amostras para treinar o modelo, enquanto os pesos amostrais são usados para atribuir “pesos” ou “importância” às amostras de treinamento.
V) Amostragem de reservatório: Já esse método é utilizado para selecionar uma amostra aleatória de dados quando não é possível armazenar todos os dados em memória. Esse método é útil para lidar com grandes volumes de dados e restrições de memória. Além disso, ele é muito útil quando se precisa lidar com dados de streaming. 
VI) Amostragem de importância: Esta é uma técnica usada para lidar com desequilíbrios nos dados, atribuindo pesos diferentes às instâncias com base em sua importância relativa para o modelo. Isso ajuda a treinar modelos mais robustos em conjuntos de dados desbalanceados, melhorando o desempenho em classes ou instâncias menos representadas.
VIII) Rótulos Neurais: São representações numéricas de palavras ou conceitos em um espaço vetorial contínuo, derivadas de modelos de linguagem neurais. Esses vetores capturam relações semânticas entre palavras e são usados em tarefas de processamento de linguagem natural. Eles têm aplicações em recuperação de informação, classificação de texto, tradução automática, análise de sentimentos, entre outras áreas. Um exemplo canônico de tarefas com rótulos naturais são os sistemas de recomendação.
IX) Desequilíbrio de classe: Ocorre quando as classes de interesse em um conjunto de dados estão distribuídas de forma desigual, com uma ou mais classes sendo muito mais frequentes do que outras. Isso pode levar a modelos que têm um bom desempenho na classe majoritária, mas falham em detectar a classe minoritária. Para lidar com isso, podem ser aplicadas técnicas como reamostragem, ponderação de classe, uso de algoritmos especializados e métricas de avaliação adequadas. A escolha da abordagem depende das características específicas do problema e dos dados disponíveis.
X) Perturbação: Ela é uma técnica que introduz pequenas variações nos dados de treinamento para melhorar a robustez e generalização do modelo. Isso pode incluir adição de ruído, remoção de características ou até mesmo rotulação incorreta de exemplos. A perturbação ajuda a prevenir o sobreajuste, aumentar a diversidade dos dados e tornar o modelo mais robusto a variações nos dados de teste. Ademais, ela também se enquadra como uma operação de preservação de rótulos, mas também é utilizada para enganar modelos que fazem previsões erradas.
Para concluir, esses insights desempenham papéis importantes na construção de modelos de Aprendizado de Máquina trazendo mais eficácia e confiabilidade, ajudando a melhorar a representatividade dos dados, a compreensão dos padrões, a capacidade de generalização e a robustez do modelo contra sobreajuste. De modo geral, os métodos de amostragem vistos ajudam a construir conjuntos de dados representativos e diversificados, melhorando a generalização do modelo. Os Rótulos Neurais fornecem representações robustas, permitindo ao modelo entender relações complexas entre os dados. O Desequilíbrio de Classe dispõe de estratégias para lidar com desequilíbrios que garantem que o modelo aprenda de forma igualitária de todas as classes, melhorando a capacidade de generalização. Já a perturbação evita sobreajuste, aumentando a robustez do modelo e sua capacidade de generalização. Por fim, esses elementos combinados são de grande auxílio para construir modelos mais precisos e confiáveis, capazes de lidar com uma variedade de desafios nos dados de entrada.






